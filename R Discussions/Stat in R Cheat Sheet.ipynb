{"metadata":{"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.6.3"},"kernelspec":{"name":"ir","display_name":"R","language":"R"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Statistical Analysis with R Cheat Sheet","metadata":{"tags":[]},"id":"a833ea7a-c915-4411-ad09-9211dde35e4b"},{"cell_type":"markdown","source":"## Base R statistical functions for central tendency and variability\n\nHere’s a selection of statistical functions having to do with central tendency and variability that come with the standard R installation. You’ll find many others in R packages.\n\nEach of these statistical functions consists of a function name immediately followed by parentheses, such as  `mean()`, and  `var()`. Inside the parentheses are the arguments. In this context, “argument” doesn’t mean “disagreement,” “confrontation,” or anything like that. It’s just the math term for whatever a function operates on.  \n\n| **Function**| **What it Calculates**|  \n| ----------- | ----------- |\n| `mean(_x_)` |Mean of the numbers in vector x.|\n|`median(_x_)`|Median of the numbers in vector x|\n|`var(_x_)`|Estimated variance of the population from which the numbers in vector x are sampled|\n|`sd(_x_)`|Estimated standard deviation of the population from which the numbers in vector x are sampled|\n|`scale(_x_)`|Standard scores (z-scores) for the numbers in vector x|\n## Base R Statistical Functions for Relative Standing\n\nHere’s a selection of R statistical functions having to do with relative standing.   \n\n| **Function**| **What it Calculates**|  \n| ----------- | ----------- |\n|`sort(x)`|The numbers in vector x in increasing order|\n|`sort(x)[n]`|The nth smallest number in vector x|\n|`rank(x)`|Ranks of the numbers (in increasing order) in vector x|\n|`rank(-x)`|Ranks of the numbers (in decreasing order) in vector x|\n|`rank(x, ties.method= “average”)`|Ranks of the numbers (in increasing order) in vector x, with tied numbers given the average of the ranks that the ties would have attained|\n|`rank(x, ties.method= “min”)`|Ranks of the numbers (in increasing order) in vector x, with tied numbers given the minimum of the ranks that the ties would have attained|\n|`rank(x, ties.method = “max”)`|Ranks of the numbers (in increasing order) in vector x, with tied numbers given the maximum of the ranks that the ties would have attained|\n|`quantile(x)`|The 0th, 25th, 50th, 75th, and 100th  percentiles (i.e, the  _quartiles_) of the numbers in vector x. (That’s not a misprint: quantile(x) returns the quartiles of x.)|\n## T-Test Functions for Statistical Analysis with R\n\nHere’s a selection of R statistical functions having to do with t-tests.\n\n|**Function**|**What it Calculates**|\n| ----------- | ----------- |\n|`t.test(x,mu=n, alternative = “two.sided”)`|Two-tailed t-test that the mean of the numbers in vector x is different from n.|\n|`t.test(x,mu=n, alternative = “greater”)`|One-tailed t-test that the mean of the numbers in vector x is greater than n.|\n|`t.test(x,mu=n, alternative = “less”)`|One-tailed t-test that the mean of the numbers in vector x is less than n.|\n|`t.test(x,y,mu=0, var.equal = TRUE, alternative = “two.sided”)`|Two-tailed t-test that the mean of the numbers in vector x is different from the mean of the numbers in vector y. The variances in the two vectors are assumed to be equal.|\n|`t.test(x,y,mu=0, alternative = “two.sided”, paired = TRUE)`|Two-tailed t-test that the mean of the numbers in vector x is different from the mean of the numbers in vector y. The vectors represent matched samples.|\n\n## ANOVA and Regression Analysis Functions for Statistical Analysis with R\n\nHere’s a selection of R statistical functions having to do with Analysis of Variance (ANOVA) and correlation and regression.\n\nWhen you carry out an ANOVA or a regression analysis, store the analysis in a list. For example,\n\n`a <- lm(y~x, data = d)`\n\nThen, to see the tabled results, use the summary() function:\n\n`summary(a)`\n\n**Analysis of Variance (ANOVA)**   \n\n|**Function**|**What it Calculates**|\n| ----------- | ----------- |\n|`aov(y~x, data = d)`|Single-factor ANOVA, with the numbers in vector y as the dependent variable and the elements of vector x as the levels of the independent variable. The data are in data frame  _d_.|\n|`aov(y~x + Error(w/x), data = d)`|Repeated Measures ANOVA, with the numbers in vector y as the dependent variable and the elements in vector x as the levels of an independent variable. Error(w/x) indicates that each element in vector w experiences all the levels of  _x_  (i.e.,  _x_  is a repeated measure). The data are in data frame d.|\n|`aov(y~x*z, data = d)`|Two-factor ANOVA, with the numbers in vector y as the dependent variable and the elements of vectors  _x_  and  _z_  as the levels of the two independent variables. The data are in data frame  _d_.|\n|`aov(y~x*z + Error(w/z), data = d)`|Mixed ANOVA, with the numbers in vector z as the dependent variable and the elements of vectors  _x_  and  _y_  as the levels of the two independent variables. Error(w/z) indicates that each element in vector  _w_  experiences all the levels of  _z_  (i.e.,  _z_  is a repeated measure). The data are in data frame  _d_.|\n\n**Correlation and Regression**   \n\n\n|**Function**|**What it Calculates**|\n| ----------- | ----------- |\n|`cor(x,y)`|Correlation coefficient between the numbers in vector  _x_  and the numbers in vector  _y_|\n|`cor.test(x,y)`|Correlation coefficient between the numbers in vector  _x_  and the numbers in vector  _y_, along with a t-test of the significance of the correlation coefficient.|\n|`lm(y~x, data = d)`|Linear regression analysis with the numbers in vector  _y_  as the dependent variable and the numbers in vector _x_  as the independent variable. Data are in data frame  _d_.|\n|`coefficients(a)`|Slope and intercept of linear regression model  _a_.|\n|`confint(a)`|Confidence intervals of the slope and intercept of linear regression model  _a_|\n|`lm(y~x+z, data = d)`|Multiple regression analysis with the numbers in vector y as the dependent variable and the numbers in vectors  _x_  and  _z_  as the independent variables. Data are in data frame _d_.|\n","metadata":{},"id":"9421074a-b6cf-4768-b6b0-b5f0aea6ba76"},{"cell_type":"markdown","source":"## Important libraries to load \nIf you don’t have a particular package installed already: install.packages(Tmisc).\n~~~\n library(readr)        # for optimized read with read_csv() instead of read.csv() \n library(dplyr)        # for filter(), mutate(), %>%, etc. see dplyr lesson. \n library(ggplot2)      # for making plots in this lesson \n library(broom)        # OPTIONAL: for model tidying with tidy(), augment(), glance() \n library(Tmisc)        # OPTIONAL: for gg_na() and propmiss()\n ~~~","metadata":{},"id":"13172af9-af24-45f1-9eca-77e308c39099"},{"cell_type":"markdown","source":"\n## The pipe: `%>% `\nWhen you load the `dplyr` library you can use `%>%`, **the pipe**. Running `x %>% f(args)` is the same as `f(x, args)`. \nIf you wanted to run function `f()` on data `x`, then run function `g()` on that, then run function `h()` on that result: instead of nesting multiple functions, `h(g(f(x)))`, it’s preferable and more readable to create a chain or pipeline of functions: `x %>% f %>% g %>% h`. \nPipelines can be spread across multiple lines, with each line ending in `%>%`   \n\n|Function  |Description  |\n|--|--|\n|`read_csv(\"path/awesome.csv\")` |Read awesome.csv in the path/ folder `library(readr)` |\n|View(df)| View tabular data frame df in a graphical viewer |\n|head(df) ; tail(df)| Print first and last few rows of data frame df |\n|mean, median, range |Descriptive stats. Remember `na.rm=TRUE` if desired |\n|is.na(x) |Returns TRUE/FALSE if NA. sum(is.na(x)) to count NAs |\n|filter(df, ..,)| Filters data frame according to condition ... (dplyr) |\n|t.test(y~grp, data=df) |T-test mean y across grp in data df |\n|wilcox.test(y~grp, data=df) |Wilcoxon rank sum / Mann-Whitney U test |\n|lmfit <- lm(y~x1+x2, data=df) |Fit linear model y against two x’s |\n|anova(lmfit) P|rint ANOVA table on object returned from lm() |\n|summary(lmfit) |Get summary information about a model fit with lm() |\n|TukeyHSD(aov(lmfit)) |ANOVA Post-hoc pairwise contrasts |\n|xt <- xtabs(~x1+x2, data=df) |Cross-tabulate a contingency table |\n|addmargins(xt) |Adds summary margin to a contingency table xt |\n|prop.table(xt) |Turns count table to proportions (remember margin=1) |\n|chisq.test(xt) |Chi-square test on a contingency table xt |\n|fisher.test(xt) |Fisher’s exact test on a contingency table xt |\n|mosaicplot(xt) |Mosaic plot for a contingency table xt |\n|factor(x, levels=c(\"wt\", \"mutant\")) |Create factor specifying level order |\n|relevel(x, ref=\"wildtype\") |Re-level a factor variable |\n|glm(y~x1+x2, data=df, family=\"binomial\") |Fit a logistic regression model |\n|power.t.test(n, power, sd, delta) |T-test power calculations |\n|power.prop.test(n, power, p1, p2)| Proportions test power calculations |\n|tidy() augment() glance()| Model tidying functions in the broom package|\n\n\n## ggplot2 basics \nBuild a plot layer-by-later, starting with a call to `ggplot()`, specifying the data and aesthetic mappings, for instance, to x/y coordinates and color. Continue building a plot by adding layers such as geometric objects *(geoms)* or statistics, like a trendline. The example below will use *mydata*, plot *xvar* and *yvar* on the *x* and *y* axes, plot points colored by levels of *groupvar*, and add a linear model trendline. \n\n`ggplot(mydata, aes(xvar, yvar)) + geom_point(aes(color=groupvar)) + geom_smooth(method=\"lm\")`","metadata":{},"id":"aaec0871-8a21-45ac-b2c7-200aeadf04f7"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"9ac0491e-7fe3-4728-94c2-af0e6da58b1f"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"97e33cfa-0076-45fd-8d72-34ae24c21dc4"}]}